# Disaster Response Pipeline Project

Udacity project - Create a Data Pipeline to triage messages for delivery to correct disaster response teams 


### Table of Contents

1. [Libraries and Installation](#installation)
2. [Project Description](#motivation)
2. [Application](#app)
3. [Files](#files)
4. [Findings](#results)

## Libraries and Installation <a name="installation"></a>

The project uses the Flask web framework, which does not require any special installation.

Python packages:
 - sqlalchemy
 - pandas
 - plotly
 - nltk
 - sklearn
 - re
 - flask
 - json
 - numpy
 - math
 - sqlite3

## Project Description<a name="motivation"></a>

This project uses a dataset provided by FigureEight consisting of messages sent during various natural disasters.
The purpose is to perform ETL operations, pipeline clean data to a SQL database, and provide a web dashboard that would be usable by disaster response agencies.

There are two data pipelines, and a web app to provide a data visualization dashboard.
 - ETL Pipeline with data cleaning
 - Machine learning pipeline with text tokenization, lemmatization, and classification by way of multi-output random forest classifier

 The project also includes Jupyter notebooks that were used to optimize the classifier.

I redesigned the web app around a REST API.  Significant changes to the Udacity template include:
 - Four HTML templates are provided - although the app is a single-page app modified by AJAX, there are /about and /contact pages, as well as a page header
 - The Python server does not render plotly objects; it passes data along to the app as JSON strings appended to HTTP responses
 - Business logic is handled by the client side script /flask-app/disaster_response/static/scripts/content.js.  The reviewer's attention is brought to this file.
 - Plotly plots are rendered client-side by way of javascript
 - I have taken advantage of some of the Bootstrap elements to make the app more interesting, for example the tabbed page
 - I have attached the Jupyter Notebooks containing the analysis steps to the project, they can be found at the /about route
 
## App Usage<a name="app"></a>

1.  Main application page

![alt text](https://github.com/ismith1024/Udacity-Disaster-Response-Data-Pipeline/blob/master/images/01Main.png "Main app page")

2.  "About" page

![alt text](https://github.com/ismith1024/Udacity-Disaster-Response-Data-Pipeline/blob/master/images/02About.png "About page")

3.  "Contact" page

![alt text](https://github.com/ismith1024/Udacity-Disaster-Response-Data-Pipeline/blob/master/images/03Contact.png "Contact page")

4.  Classifying a message

Note the radio buttons to tell the server the genre of the incoming message.  Please note that all disaster categories are passed by the server, but only the applicable ones are displayed to the user.

![alt text](https://github.com/ismith1024/Udacity-Disaster-Response-Data-Pipeline/blob/master/images/04Classify.png "Message classifier")

5.  First visualization: Messages from past events, by genre

![alt text](https://github.com/ismith1024/Udacity-Disaster-Response-Data-Pipeline/blob/master/images/05vis1.png "First visualization")

6.  Second visualization: Messages from past events, by class

![alt text](https://github.com/ismith1024/Udacity-Disaster-Response-Data-Pipeline/blob/master/images/06vis2.png "Second visualization")

7.  Third visualization: Messages from current disaster (i.e. classified during current browsing session), by class and genre

![alt text](https://github.com/ismith1024/Udacity-Disaster-Response-Data-Pipeline/blob/master/images/07vis3a.png "Third visualization")
![alt text](https://github.com/ismith1024/Udacity-Disaster-Response-Data-Pipeline/blob/master/images/08vis3b.png "Third visualization")

## Files <a name="files"></a>

Files and directories in parentheses are not generated by me and are not expected to interest the project reviewer

- flask-app
  - disaster-response
    - static
      - scripts
        - content.js
        - (several other scripts)
      - (other directories)
    -templates
      - about.html #the Jupyter Notebooks where I performed preliminary data analysis
      - contact.html #a little information about me and hte project repository
      - index.html #the app's main page
      - (other html pages)
|- run.py  # Flask file that runs app

- data
  - disaster_categories.csv  # data to process 
  - disaster_messages.csv  # data to process
  - process_data.py
  - disaster_data.db   # database to save clean data to

- models
  - train_classifier.py
  - model.pkl  # saved model 

## Findings<a name="results"></a>

- The classifier works okay, here are some messages that give interesting results:
    - 'send food my family is super hungry'
    - 'my house is flooding'
    - 'There is a tornado approaching'
    - 'three people died so far'
    - 'earthquake this morning'
    - 'There is a big fire and stuff is burning'
    - 'We are thirsty and need water and supplies'
    - 'Send medicine we are sick and have a fever'
    - 'Wind gusts exceeding 50 knots'
    - 'Landslides have destroyed many homes and left families homeless'
- Some other messages that would appear to be relevant were missed by the classifier.
- The grid search was difficult to evaluate in a manageable amount of time.  I had to cut the parameter grid down to a very rudimentary searhc in order to meet both my own time constraints and Github's storage constraints
- I evaluated the Adaboost classifier as well as the random forest.  It slightly outperformed Random Forest on precision, but severely underperformed on recall



